---
title: "Análise de Personalidade de Clientes - Clusters"
author: "Gleynner Ghiotto"
output:
  html_document:
    df_print: paged
#    number_sections: true
    toc: true
#    toc_float: true
    toc_depth: 3
    theme: readable
    highlight: pygments
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align='center',comment = "")
```

<style> body {text-align: justify} </style>

```{r, message = FALSE}
# Carregar pacotes utilizados nesta etapa:

library(tidyverse)
library(factoextra)
library(reshape2)
```


```{r, include=FALSE}
##
round_df <- function(x, digits) {
    # round all numeric variables
    # x: data frame 
    # digits: number of digits to round
    numeric_columns <- sapply(x, mode) == 'numeric'
    x[numeric_columns] <-  round(x[numeric_columns], digits)
    x
}

```


# Carregar dados

Carregar conjunto de dados trabalhado na etapa de pré-processamento e análise exploratória de dados (EDA).

```{r, comment=""}
df_eda <- read.csv("df_eda_marketing_campaign.csv",
                  header = TRUE)
head(df_eda, n=10)
```


# Gerar clusters


A ideia principal da Análise de Cluster é a possibilidade de classificar os objetos em grupos, de forma que, dentro de um mesmo grupo, os objetos sejam o mais similares possível e, de forma análoga, que os diversos grupos (clusters) sejam o mais diferente possível em sua constituição. Como este tipo de aprendizado é não supervisionado, os dados não possuem rótulos e o algoritmo aprende as relações entre eles. 

O algoritmo K-means começa com a inicialização aleatória de k centroides. Para cada ponto do conjunto de dados, calcula-se a distância até os centroides e os pontos são atribuídos ao cluster cujo centroide está mais próximo dele. Após essa atribuição, a posição de cada centroide é recalculada por meio da média dos pontos pertencentes de cada cluster. O processo de atribuição de pontos e o recalculo dos centroides é repetido até que as posições dos centroides se estabilizem, ou seja, não ocorram mudanças significativas.


```{r, comment="", fig.align='center'}
nomes <- c("Income","Kidhome","MntFruits","MntMeatProducts","MntFishProducts","MntSweetProducts",
           "NumWebPurchases","NumCatalogPurchases","NumStorePurchases","NumWebVisitsMonth","Idade",
           "N_Children","Gasto_total","Numero_compras","Valor_medio_de_compra","Class_VMC")

df_cluster <- df_eda[,nomes[-16]] 
  
X1 <- df_cluster %>% scale()

```

```{r, comment="", fig.align='center'}
set.seed(1)
wcss = vector()
for (i in 1:10) {
  kmeans = kmeans(x = X1, centers = i)
  wcss[i] = sum(kmeans$withinss)
}

ggplot(data = data.frame(n = c(1:10),WCSS = wcss),aes(x = n, y=WCSS)) +
  geom_line(linewidth=0.7,linetype = 1,lineend	= "round",linejoin = "round",linemitre=1) + 
  geom_point(size = 2.5) +
  labs(x="Número de clusters (k)",y="WCSS", title="Método de Elbow") +
  scale_x_continuous(breaks = seq(0,10,2)) +
  theme_bw()
```

O método de Elbow, também conhecido como método do cotovelo, é um gráfico onde eixo x representa o número de clusters (k) e o eixo y representa a soma dos quadrados das distâncias de cada ponto ao centroide de seu respectivo cluster (WCSS, Within-Cluster Sum of Squares). O objetivo é encontrar um ponto no gráfico onde a diminuição da soma do WCSS se torna menos acentuada, formando um "cotovelo". Esse ponto indica um bom número de clusters, pois é onde adicionar mais clusters não traz uma redução significativa da compacidade dos clusters.

Para o exemplo em questão, utilizaremos 3 clusters, pois, a partir desse ponto, a redução do WCSS em função do número de clusters torna-se menos acentuada.

```{r, comment="", fig.align='center'}
set.seed(1)
kmeans = kmeans(x = X1, centers = 3)
previsoes = kmeans$cluster

X1 <- as.data.frame(X1)
```


```{r}
fviz_cluster(kmeans, X1,
             main = "Clusters - K-means",
             ggtheme = theme_minimal()) +
  geom_hline(aes(yintercept =0), linetype = 2) +
  geom_vline(aes(xintercept =0), linetype = 2) 
```


```{r}
data.frame(Cluster = previsoes,
           Valor_medio_de_compra = df_cluster$Valor_medio_de_compra,
           df_cluster %>% select(-"Valor_medio_de_compra"),
           check.names = F) %>% dplyr::group_by(Cluster) %>% 
  dplyr::summarise_all(list(mean)) %>% t() %>% as.data.frame() %>% 
  .[-1,] %>% round_df(2)

```

Por meio dos clusters formados, o grupo de número 1 é composto pelos clientes com o maior valor médio de compra, isto é, o grupo em que o gasto total dividido pelo número de compras é maior. Nesse grupo, os clientes têm maior renda média anual e tendem a possuir menor número de filhos. Nota-se também que este perfil de clientes possui maiores gastos com frutas, produtos cárneos, pesqueiros e doces. Ainda, eles têm preferência por realizar suas compras por meio da loja física e catálogo, sendo o tipo de pessoas que menos visita o site da empresa. 

O grupo 2 possui um perfil intermediário, possuindo nível de compra não tão alto quanto o grupo 1 e nem tão baixo quanto o grupo 3. Esse perfil de clientes são os que mais utilizam o web site da empresa para fazer suas compras. Já o grupo 3 possui um perfil mais conservador, sendo formado pelos clientes que possuem maior número de crianças em casa e é o grupo que mais visitou o web site da empresa no último mês (possivelmente em busca de promoções).

Abaixo segue uma representação da tabela acima, represantada por seus valores em escala, onde: os valores positivos represantam gastos acima da média; valores negativos representam gastos abaixo da média; e, valores iguais a zero, gastos iguais ao valor médio.

```{r}
cluster_summary <- data.frame(Cluster = previsoes,
                        rev(X1) %>% select(-"Valor_medio_de_compra"), 
                        Valor_medio_de_compra = df_cluster$Valor_medio_de_compra,
                        check.names = F) %>% dplyr::group_by(Cluster) %>% 
  dplyr::summarise_all(list(mean)) 
melt_cluster_summary <- melt(as.matrix(cluster_summary[,-1]))

ggplot(melt_cluster_summary, aes(Var2, Var1)) +
  scale_fill_continuous(type = "viridis", direction = -1) +
  geom_tile(aes(fill = value)) +
  geom_text(aes(label = round(value, 1))) +
  theme_bw() +
  ggtitle("Strength of Each of the Variables in the Clusters") +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(x="Variable", y="Cluster") +
  coord_flip()
```





